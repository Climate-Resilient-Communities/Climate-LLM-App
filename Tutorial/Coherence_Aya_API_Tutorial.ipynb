{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "Wz8Au3-ZjAUQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q fastapi cohere"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "from getpass import getpass\n",
        "# Set up Cohere client and choose model\n",
        "co_api_key = getpass(\"Enter Cohere API key: \")\n",
        "co = cohere.Client(api_key=co_api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlKidez79drD",
        "outputId": "68b25b38-cac8-4351-89a5-e84845eb1fa5"
      },
      "execution_count": 97,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Cohere API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### What models are in cohere lets find \"aya\"\n",
        "import requests\n",
        "\n",
        "url = \"https://api.cohere.ai/v1/models\"\n",
        "\n",
        "headers = {\"accept\": \"application/json\",\"Authorization\":f\"Bearer {co_api_key}\"}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40C8xL-K4-cb",
        "outputId": "583a6d96-cf21-4cc0-c3da-1026019d107f"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"models\":[{\"name\":\"embed-english-light-v2.0\",\"endpoints\":[\"embed\",\"classify\"],\"finetuned\":false,\"context_length\":512,\"tokenizer\":null,\"tokenizer_url\":null},{\"name\":\"embed-english-v2.0\",\"endpoints\":[\"embed\",\"classify\"],\"finetuned\":false,\"context_length\":512,\"tokenizer\":null,\"tokenizer_url\":null},{\"name\":\"embed-multilingual-light-v3.0\",\"endpoints\":[\"embed\",\"classify\"],\"finetuned\":false,\"context_length\":512,\"tokenizer\":\"embed-multilingual-v3\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/embed-multilingual-v3.json\"},{\"name\":\"command-r\",\"endpoints\":[\"generate\",\"chat\",\"summarize\"],\"finetuned\":false,\"context_length\":128000,\"tokenizer\":\"command-v2\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/command-v2.json\"},{\"name\":\"embed-multilingual-v3.0\",\"endpoints\":[\"embed\",\"classify\"],\"finetuned\":false,\"context_length\":512,\"tokenizer\":\"embed-multilingual-v3\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/embed-multilingual-v3.json\"},{\"name\":\"embed-multilingual-v2.0\",\"endpoints\":[\"embed\",\"classify\"],\"finetuned\":false,\"context_length\":256,\"tokenizer\":\"embed-multilingual-v2\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/embed-multilingual-v2.json\"},{\"name\":\"command-light-nightly\",\"endpoints\":[\"generate\",\"summarize\",\"chat\"],\"finetuned\":false,\"context_length\":4096,\"tokenizer\":\"command-v1\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/command-v1.json\"},{\"name\":\"rerank-multilingual-2\",\"endpoints\":[\"rerank\"],\"finetuned\":false,\"context_length\":512,\"tokenizer\":\"rerank-multilingual-v2\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/rerank-multilingual-v2.json\"},{\"name\":\"command-r-no-lc\",\"endpoints\":[\"generate\",\"chat\",\"summarize\"],\"finetuned\":false,\"context_length\":8192,\"tokenizer\":\"command-v2\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/command-v2.json\"},{\"name\":\"embed-english-v3.0\",\"endpoints\":[\"embed\",\"classify\"],\"finetuned\":false,\"context_length\":512,\"tokenizer\":\"embed-english-v3\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/embed-english-v3.json\"},{\"name\":\"command\",\"endpoints\":[\"generate\",\"summarize\",\"chat\"],\"finetuned\":false,\"context_length\":4096,\"tokenizer\":\"command-v1\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/command-v1.json\"},{\"name\":\"command-nightly\",\"endpoints\":[\"generate\",\"chat\",\"summarize\"],\"finetuned\":false,\"context_length\":128000,\"tokenizer\":\"command-v2\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/command-v2.json\"},{\"name\":\"rerank-english-2\",\"endpoints\":[\"rerank\"],\"finetuned\":false,\"context_length\":512,\"tokenizer\":\"rerank-english-v2\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/rerank-english-v2.json\"},{\"name\":\"command-light\",\"endpoints\":[\"generate\",\"summarize\",\"chat\"],\"finetuned\":false,\"context_length\":4096,\"tokenizer\":\"command-v1\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/command-v1.json\"},{\"name\":\"c4ai-aya\",\"endpoints\":[\"generate\"],\"finetuned\":false,\"context_length\":4096,\"tokenizer\":\"command-v2\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/command-v2.json\"},{\"name\":\"embed-english-light-v3.0\",\"endpoints\":[\"embed\",\"classify\"],\"finetuned\":false,\"context_length\":512,\"tokenizer\":\"embed-english-v3\",\"tokenizer_url\":\"https://storage.googleapis.com/cohere-assets/tokenizers/embed-english-v3.json\"}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We found c4ai-aya now lets set up the model\n",
        "co_model = 'c4ai-aya'"
      ],
      "metadata": {
        "id": "FHCmqkogzGBW"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what country is the largest in the World?\""
      ],
      "metadata": {
        "id": "W1OAeAqClJrH"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = co.generate(\n",
        "  prompt=query,\n",
        "  model=co_model,\n",
        "  max_tokens=300,\n",
        "  temperature=0.9,\n",
        "  k=0\n",
        ")\n",
        "response = response\n",
        "print('Prediction: {}'.format(response.generations[0].text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmJh7xw1shdA",
        "outputId": "d1edde62-cba3-4243-c8a4-9038c6e7edfa"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: There are multiple ways that large can be defined. By area, Russia is the largest country in the world alternatively by Population, China is the worlds most populated country.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Lets try in spanish by creating a pipeline to avoid rewriting the function every time\n",
        "def run_pipeline(query):\n",
        "    response = co.generate(\n",
        "        prompt=query,\n",
        "        model=co_model,\n",
        "        max_tokens=300,\n",
        "        temperature=0.9,\n",
        "        k=0\n",
        "    )\n",
        "    print('Prediction: {}'.format(response.generations[0].text))\n",
        "\n",
        "# Now you can run the pipeline with a new query like this:\n",
        "run_pipeline(\"Que pais es el mas grande del mundo?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBf1vDde_2SC",
        "outputId": "f84da100-0056-45fc-d47d-c6491f52e84a"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: El pais mas grande del mundo es Rusia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Final check in mandarin of what country is the biggest in the world\n",
        "\n",
        "run_pipeline(\"哪个国家是世界上最大的\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0GdPkWKAhhL",
        "outputId": "535fde53-8c97-4151-ee13-7d7c83e2c641"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 世界上有很多方法可以定义大. 按面积计算,俄罗斯是世界上最大的国家,按人口计算,中国是世界上人口最多的国家.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MRhgf6joAwyr"
      }
    }
  ]
}